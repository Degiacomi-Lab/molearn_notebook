{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOLEARN ANALYSIS TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[molearn](https://github.com/Degiacomi-Lab/molearn) is a convolutional generative neural network trainable with protein conformations. Its architecture and benchmarking is described in [ V.K. Ramaswamy et al. (2021). *Learning protein conformational space with convolutions and latent interpolations*, Physical Review X 11](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.11.011052). This tutorial is dedicated to demonstrating how to use *molearn* after it is trained, and how to characterize its performance. It is divided in the following sections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Load neural network and training set](#ref1)\n",
    "   - [1.1. The data](#ref11)\n",
    "   - [1.2. Data loading](#ref12)\n",
    "   - [1.3. Loading the neural network](#ref13)\n",
    "   \n",
    "   \n",
    "[2. Projection into latent space and back](#ref2)\n",
    " \n",
    " \n",
    "[3. Dataset analysis](#ref3)\n",
    "   -  [3.1. RMSD (or MSE) of input vs autoencoded](#ref31)\n",
    "   -  [3.2. DOPE score of input vs autoencoded](#ref32)\n",
    "   \n",
    "   \n",
    "[4. Full latent space characterization](#ref4)\n",
    "   - [4.1. Evaluate re-encoding error](#ref41)\n",
    "   - [4.2. Evaluate DOPE score](#ref42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, let's load some packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "\n",
    "import nglview as nv\n",
    "import MDAnalysis as mda\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import modeller\n",
    "from modeller import *\n",
    "from modeller.scripts import complete_pdb\n",
    "\n",
    "import biobox as bb\n",
    "\n",
    "#edit path as required for your computer (or remove, if you installed molearn via conda-forge)\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\xdzl45\\\\workspace\\\\molearn\\\\src\")\n",
    "from molearn import load_data, Auto_potential, Autoencoder, ResidualBlock\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load neural network and training set <a class=\"anchor\" id=\"ref1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. the data <a class=\"anchor\" id=\"ref11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MurD is a 47-kDa ATP-driven ligase responsible for the biosynthesis of a bacterial peptidoglycan precursor (UDP-N-acetylmuramoyl-L-alanyl-D-glutamate). When bound to its ligand, UDP-N-acetylmuramoyl-L-alanyl-D-alanine, MurD is stabilized in a closed conformation (PDB: [3UAG](https://www.rcsb.org/structure/3UAG)). In the absence of UDP-N-acetylmuramoyl-L-alanyl-D-alanine, MurD takes instead an open conformation (PDB: [1E0D](https://www.rcsb.org/structure/1E0D)). We have carried out molecular dynamics simulations of both states. For this tutorial, we will load a multi-PDB file containing a subset of conformations of both trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining the files containing the training set (variable `training_set_file`), and test set (variable `test_set_file`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_file = f'data{os.sep}MurD_closed_open_strided.pdb'\n",
    "test_set_file = f'data{os.sep}MurD_closed_apo_strided.pdb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set contains a concatenation of MD simulations of the closed and open states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5836a2f62c45f79150191304dd8dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=379)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "universe_training = mda.Universe(training_set_file)\n",
    "w = nv.show_mdanalysis(universe_training)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking the closed conformation and manually removing the ligand, the protein switches to an open conformation. This is the simulation we will used as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fa27a42f514e8abbe6547f14e4d112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=99)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "universe_test = mda.Universe(test_set_file)\n",
    "w = nv.show_mdanalysis(universe_test)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. data loading <a class=\"anchor\" id=\"ref12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now prepare the training set, transforming into a `Tensor` an making sure to extract from it only the atoms actually used during neural network training (CA, C, N, O, CB). This yields:\n",
    " - `training_set`, a pyTorch `Tensor` containing a desired subset of *normalized* atomic coordinates ready for submission to the neural network.\n",
    " - `meanval` and `stdval`, the mean and standard deviation of the original input data, useful to rescale generated structures into atomic coordinates.\n",
    " - `atom_names` list containing the names of atoms in the training set (in the same order)\n",
    " - `mol`, a  `biobox` instance corresponding to the coordinates in `training_set`, useful as a PDB writer and offering useful helper functions, e.g. RMSD calculation.\n",
    " - `test0` and `test1`, `biobox` instances of the two most extreme conformations by RMSD in the loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting rmsd from file:  rmsd_matrix.npy\n",
      "Conformations: (also saved to dataset_conformations.npy)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "training_set, meanval, stdval, atom_names, mol, test0, test1 = load_data(training_set_file, atoms = [\"CA\", \"C\", \"N\", \"CB\", \"O\"], device=device)\n",
    "os.remove(\"rmsd_matrix.npy\") # needed to prevent loading of incorrect distance matrix calculated for training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`training_set` takes the form of a Nx3xM normalised `Tensor` object, where N is the number of examples, M the number of atoms, and 3 the x, y, z coordinates of each atom. This is the order of dimensions required by the neural network, a typical multiPDB has columns in the NxMx3 order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([380, 3, 2145])\n"
     ]
    }
   ],
   "source": [
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the test set in the same way as the training set. This time, we will only retain the coordinates of atoms, normalised and ready to be submitted to the neural network (discarding all other outputs). The test set must contain the same atoms as the training set, in the same order. The two datasets should also be aligned, since *molearn* is not rototranslation invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting rmsd from file:  rmsd_matrix.npy\n",
      "rmsd_from_file: rmsd_matrix.npy is not a valid filename or doesnt exist\n",
      "rmsd not found therefore I have to calculate it\n",
      "rmsd calcs Done\n",
      "Conformations: (also saved to dataset_conformations.npy)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "test_set = load_data(test_set_file, atoms = [\"CA\", \"C\", \"N\", \"CB\", \"O\"], device=device)[0]\n",
    "os.remove(\"rmsd_matrix.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. loading the neural network <a class=\"anchor\" id=\"ref13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the parameters of a trained neural network saved in the following file (variable `networkfile`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkfile = f'data{os.sep}conv1d-physics-path_B.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the parameters passed to the `Autoencoder` costructor need to be the same as those used to build the trained neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): ModuleList(\n",
       "    (0): Conv1d(3, 32, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(32, 64, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv1d(64, 128, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (9): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (14): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv1d(256, 512, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (19): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (22): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (23): Conv1d(512, 2, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (24): To2D()\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): From2D(\n",
       "      (f): Linear(in_features=2, out_features=52, bias=True)\n",
       "    )\n",
       "    (1): ConvTranspose1d(2, 1024, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose1d(1024, 512, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): ConvTranspose1d(512, 256, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (10): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (15): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (19): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (20): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (23): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (24): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
       "    (25): BatchNorm1d(32, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (28): ResidualBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=1.0, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (29): ConvTranspose1d(32, 3, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(networkfile, map_location=device)\n",
    "network = Autoencoder(m=2.0, latent_z=2, r=2).to(device)\n",
    "network.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "for modulelist in [network.encoder, network.decoder]:\n",
    "    for layer in modulelist:\n",
    "        if type(layer)==torch.nn.BatchNorm1d:\n",
    "            layer.momentum=1.0\n",
    "        elif type(layer)==ResidualBlock:\n",
    "            for rlayer in layer.conv_block:\n",
    "                if type(rlayer)==torch.nn.BatchNorm1d:\n",
    "                    rlayer.momentum=1.0\n",
    "                    \n",
    "with torch.no_grad():\n",
    "    network.decode(network.encode(training_set.float()))\n",
    "\n",
    "network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.0122, -0.0016, -0.2114, -0.0050],\n",
      "         [ 0.0131, -0.0289,  0.2826, -0.0188],\n",
      "         [ 0.1073,  0.2462, -0.0540, -0.1305]],\n",
      "\n",
      "        [[ 0.0204,  0.0966,  0.2575,  0.0352],\n",
      "         [ 0.1507,  0.2260,  0.1851,  0.1638],\n",
      "         [ 0.2392, -0.2715,  0.2394, -0.2594]],\n",
      "\n",
      "        [[ 0.0880,  0.1622,  0.0678,  0.0646],\n",
      "         [-0.0036,  0.0578,  0.0830,  0.0743],\n",
      "         [ 0.0460,  0.1689, -0.0645, -0.1900]],\n",
      "\n",
      "        [[ 0.0079,  0.1598, -0.0719, -0.0257],\n",
      "         [-0.2442, -0.2214, -0.2144,  0.0186],\n",
      "         [ 0.1921, -0.2553,  0.1015, -0.2609]],\n",
      "\n",
      "        [[ 0.1465,  0.2726, -0.1212,  0.2597],\n",
      "         [-0.1745, -0.1644, -0.2420, -0.0685],\n",
      "         [ 0.2188, -0.1395,  0.1054, -0.2616]],\n",
      "\n",
      "        [[-0.1297, -0.0097, -0.1454, -0.0065],\n",
      "         [ 0.2239,  0.1163, -0.0086, -0.1595],\n",
      "         [ 0.0008,  0.1385,  0.0447, -0.2543]],\n",
      "\n",
      "        [[-0.0501, -0.0960,  0.1117, -0.1005],\n",
      "         [-0.1673, -0.2050, -0.0122,  0.0680],\n",
      "         [-0.1968,  0.0096,  0.2583, -0.1401]],\n",
      "\n",
      "        [[-0.0177,  0.2728,  0.0570,  0.0915],\n",
      "         [-0.2194, -0.1782, -0.2365,  0.0899],\n",
      "         [-0.1510, -0.2417,  0.2637,  0.1989]],\n",
      "\n",
      "        [[ 0.1706,  0.1246,  0.1377, -0.0021],\n",
      "         [-0.2350,  0.1617,  0.0467,  0.0679],\n",
      "         [-0.2191, -0.1872,  0.2808,  0.1148]],\n",
      "\n",
      "        [[-0.1265,  0.2784,  0.1560, -0.2814],\n",
      "         [ 0.2239,  0.2173,  0.0847, -0.0111],\n",
      "         [-0.1328, -0.0809, -0.1931,  0.0096]],\n",
      "\n",
      "        [[ 0.2220, -0.1474,  0.1876, -0.1933],\n",
      "         [ 0.1623,  0.1132,  0.0876, -0.0203],\n",
      "         [-0.2108,  0.0034, -0.2523, -0.0562]],\n",
      "\n",
      "        [[ 0.0497, -0.1379, -0.0732, -0.1800],\n",
      "         [ 0.0394,  0.2268, -0.0141, -0.2610],\n",
      "         [ 0.0187, -0.0046, -0.0630, -0.1595]],\n",
      "\n",
      "        [[-0.1857,  0.2599,  0.0277,  0.2795],\n",
      "         [ 0.2637, -0.1097,  0.2074, -0.0100],\n",
      "         [-0.2544,  0.2709, -0.2353, -0.1717]],\n",
      "\n",
      "        [[-0.1871, -0.2784, -0.0834,  0.0852],\n",
      "         [-0.0161,  0.0243,  0.0210, -0.0190],\n",
      "         [ 0.1396, -0.0731,  0.2431, -0.0858]],\n",
      "\n",
      "        [[ 0.0450, -0.2523,  0.0995, -0.1387],\n",
      "         [-0.1287,  0.2314, -0.2083, -0.0241],\n",
      "         [-0.1304, -0.1123,  0.2034, -0.1004]],\n",
      "\n",
      "        [[ 0.1719, -0.1609,  0.1369, -0.2559],\n",
      "         [-0.2662,  0.0228, -0.0193,  0.2511],\n",
      "         [-0.1195,  0.2541,  0.1535, -0.2251]],\n",
      "\n",
      "        [[ 0.2371, -0.1454, -0.1688,  0.2634],\n",
      "         [ 0.1162,  0.1376, -0.2245,  0.2600],\n",
      "         [ 0.1108,  0.1248, -0.1050,  0.0715]],\n",
      "\n",
      "        [[-0.1274, -0.0896, -0.1510,  0.2555],\n",
      "         [-0.2392,  0.2683, -0.0230,  0.2744],\n",
      "         [-0.1448, -0.0673,  0.2618, -0.2366]],\n",
      "\n",
      "        [[ 0.1197, -0.2290, -0.1740, -0.2493],\n",
      "         [ 0.2245,  0.2436, -0.0322, -0.1356],\n",
      "         [ 0.2516,  0.0581,  0.0849,  0.0902]],\n",
      "\n",
      "        [[ 0.1058, -0.0574,  0.1704,  0.2553],\n",
      "         [-0.0268,  0.1532,  0.2314, -0.2532],\n",
      "         [ 0.0859, -0.2630,  0.2059,  0.2013]],\n",
      "\n",
      "        [[-0.1323,  0.2084,  0.0402, -0.2558],\n",
      "         [ 0.2332, -0.2423,  0.0034,  0.2739],\n",
      "         [-0.0216,  0.2286,  0.2607,  0.1424]],\n",
      "\n",
      "        [[ 0.2517, -0.1992,  0.0688,  0.1379],\n",
      "         [-0.2760,  0.0854, -0.0930, -0.0565],\n",
      "         [-0.2024,  0.0711,  0.0905,  0.2768]],\n",
      "\n",
      "        [[-0.0063,  0.1107,  0.1049, -0.1267],\n",
      "         [ 0.2208,  0.0368,  0.1403,  0.1862],\n",
      "         [ 0.0524, -0.1888,  0.0404, -0.1960]],\n",
      "\n",
      "        [[ 0.1033, -0.0634, -0.0842,  0.1390],\n",
      "         [ 0.0117, -0.1458, -0.0022, -0.1802],\n",
      "         [ 0.0880,  0.2511, -0.1888,  0.0578]],\n",
      "\n",
      "        [[ 0.0700,  0.2125,  0.2745,  0.1651],\n",
      "         [ 0.2402,  0.0455,  0.0516,  0.1083],\n",
      "         [ 0.0749, -0.1124, -0.2810, -0.1616]],\n",
      "\n",
      "        [[ 0.2648,  0.0158, -0.1220,  0.2698],\n",
      "         [-0.0778,  0.1302, -0.1394, -0.0793],\n",
      "         [ 0.1576, -0.2459, -0.1604,  0.1946]],\n",
      "\n",
      "        [[ 0.2503, -0.1961,  0.1884, -0.1758],\n",
      "         [-0.1206, -0.1499,  0.1261, -0.1682],\n",
      "         [-0.2522, -0.2352, -0.0703,  0.1224]],\n",
      "\n",
      "        [[-0.1766,  0.2645,  0.2283, -0.1548],\n",
      "         [-0.1422,  0.0767,  0.0129,  0.2382],\n",
      "         [-0.1870,  0.1139,  0.1545, -0.0850]],\n",
      "\n",
      "        [[ 0.1087, -0.0148, -0.2717, -0.1035],\n",
      "         [-0.2513, -0.0333, -0.0893, -0.1769],\n",
      "         [ 0.2402,  0.1682, -0.1187,  0.0373]],\n",
      "\n",
      "        [[ 0.1084,  0.1904,  0.1286,  0.1875],\n",
      "         [ 0.0569, -0.0977, -0.0549,  0.2279],\n",
      "         [ 0.1019,  0.0980,  0.0462, -0.0092]],\n",
      "\n",
      "        [[ 0.1839,  0.0962,  0.2356, -0.2757],\n",
      "         [ 0.1112, -0.0305, -0.2712, -0.0893],\n",
      "         [ 0.1616, -0.2036,  0.2176, -0.2359]],\n",
      "\n",
      "        [[ 0.0258,  0.2298, -0.0189,  0.2029],\n",
      "         [ 0.0876,  0.2048,  0.0379, -0.2381],\n",
      "         [-0.2153, -0.2076,  0.2124,  0.2756]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.encoder[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Projection into latent space and back <a class=\"anchor\" id=\"ref2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by projecting the whole training set into the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = network.encode(training_set.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`z` is a (Nx2x1) `Tensor` object, featuring the projection in the latent space of each of the N examples in the training set. If this notebook is running with a computer with a GPU, it will be stored in its memory. To get the data so we can plot it, we should move it back to the CPU, and remove one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_training = z.data.cpu().numpy()[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`z` can be decoded back into structures that, hopefully, will closely resemble the training set. Note that we clip the output to the size of dataset's degrees of freedom (an extra padding is present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  \n",
    "    decoded_training = network.decode(z)[:, :, :training_set.shape[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`decoded_training` is a now `Tensor` object stored in the GPU with the same dimensionality as the input `training_set`, and features normalised atomic coordinates. While it can already be directly compared with `training_set`, to obtain an actual protein structure we can observe, we should reorder the columns, move the data onto the CPU and \"un-normalise\" them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_protein = decoded_training[:, :, :training_set.shape[2]].data.cpu().numpy().transpose(0, 2, 1)\n",
    "print(decoded_protein.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's repeat encoding and decoding with the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = network.encode(test_set.float())\n",
    "    z_test = z.data.cpu().numpy()[:, :, 0]\n",
    "    decoded_test = network.decode(z)[:, :, :test_set.shape[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. dataset analysis <a class=\"anchor\" id=\"ref3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. RMSD (or MSE) of input vs autoencoded <a class=\"anchor\" id=\"ref31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to evaluate the performance of the network, is to compare protein conformations before they are submitted to the neural network, and after they get encoded and decoded. Note that reporting such results for the training set only is poor practice, an independent test set should be submitted to evaluate the ability of the network to generalize beyond the examples provided for training. Let's calculate the MSE of both training and test sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(network, dataset, meanval, stdval, align=False, mol=\"\"):\n",
    "    '''\n",
    "    Calculate the reconstruction error of a dataset encoded and decoded by a trained neural network\n",
    "    '''\n",
    "\n",
    "    z = network.encode(dataset.float())\n",
    "    decoded = network.decode(z)[:,:,:dataset.shape[2]]\n",
    "    \n",
    "    err = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "\n",
    "        crd_ref = dataset[i].permute(1,0).unsqueeze(0).data.cpu().numpy()*stdval + meanval\n",
    "        crd_mdl = decoded[i].permute(1,0).unsqueeze(0).data.cpu().numpy()[:, :dataset.shape[2]]*stdval + meanval #clip the padding of models  \n",
    "\n",
    "        if align: # use Molecule Biobox class to calculate RMSD\n",
    "            mol.coordinates = deepcopy(crd_ref)\n",
    "            mol.set_current(0)\n",
    "            mol.add_xyz(crd_mdl[0])\n",
    "            rmsd = mol.rmsd(0, 1)\n",
    "        else:\n",
    "            rmsd = np.sqrt(np.sum((crd_ref.flatten()-crd_mdl.flatten())**2)/crd_mdl.shape[1]) # Cartesian L2 norm\n",
    "\n",
    "        err.append(rmsd)\n",
    "\n",
    "    return np.array(err)\n",
    "    \n",
    "rmsd_training = get_error(network, training_set, meanval, stdval)\n",
    "rmsd_test = get_error(network, test_set, meanval, stdval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to produce two nice violin plots, reporting on the error of training and test set. Typically the latter will be slightly higher than the former, though ideally this difference should be as small as possible, indicating that the neural network can generalize well to structures it has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.violinplot([rmsd_training, rmsd_test], showmeans=True)\n",
    "ax.set_ylabel(\"RMSD / $\\AA$\")\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels([\"training set\", \"test set\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. DOPE score of input vs autoencoded <a class=\"anchor\" id=\"ref32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DOPE score is a heuristic function used to estimate the energy of a protein conformation. It is used by software like Modeller to define whether a protein model is accurate. Here, we start by defining a function calculating the DOPE score of a PDB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dope_score(fname):\n",
    "    env = Environ()\n",
    "    env.libs.topology.read(file='$(LIB)/top_heav.lib')\n",
    "    env.libs.parameters.read(file='$(LIB)/par.lib')\n",
    "    mdl = complete_pdb(env, fname)\n",
    "    atmsel = Selection(mdl.chains[0])\n",
    "    score = atmsel.assess_dope()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive value for a DOPE score indicates that the distriution of atoms is not what one should expect from a correct protein conformation (i.e. the protein structure is bad). However, a negative DOPE score does not immediately tell us how good the structure is. To tell whether the models generated by the neural network are good, we will compare their DOPE score with the DOPE score of the input dataset, that we can assume being good. We now calculate the DOPE score of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dope(network, dataset, meanval, stdval, mol):\n",
    "    \n",
    "    # set residues names with protonated histidines back to generic HIS name (needed by DOPE score function)\n",
    "    testH = mol.data[\"resname\"].values\n",
    "    testH[testH == \"HIE\"] = \"HIS\"\n",
    "    testH[testH == \"HID\"] = \"HIS\"\n",
    "    mol.data[\"resname\"] = testH\n",
    "\n",
    "    z = network.encode(dataset.float())\n",
    "    decoded = network.decode(z)[:,:,:dataset.shape[2]]\n",
    "    \n",
    "    dope_dataset = []\n",
    "    dope_decoded = []\n",
    "    for i in range(dataset.shape[0]):\n",
    "\n",
    "        # calculate DOPE score of input dataset\n",
    "        crd_ref = dataset[i].permute(1,0).unsqueeze(0).data.cpu().numpy()*stdval + meanval\n",
    "        mol.coordinates = deepcopy(crd_ref)\n",
    "        mol.write_pdb(\"tmp.pdb\")\n",
    "        s = dope_score(\"tmp.pdb\")\n",
    "        dope_dataset.append(s)\n",
    "\n",
    "        # calculate DOPE score of decoded counterpart\n",
    "        crd_mdl = decoded[i].permute(1,0).unsqueeze(0).data.cpu().numpy()[:, :dataset.shape[2]]*stdval + meanval  \n",
    "        mol.coordinates = deepcopy(crd_mdl)\n",
    "        mol.write_pdb(\"tmp.pdb\")\n",
    "        s = dope_score(\"tmp.pdb\")\n",
    "        dope_decoded.append(s)\n",
    "    \n",
    "    return dope_dataset, dope_decoded\n",
    " \n",
    "dope_training, dope_training_decoded = get_dope(network, training_set, meanval, stdval, mol)\n",
    "dope_test, dope_test_decoded = get_dope(network, test_set, meanval, stdval, mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "violins = ax.violinplot([dope_training, dope_training_decoded, dope_test, dope_test_decoded],\n",
    "                        showmeans = True, showextrema = True)\n",
    "\n",
    "ax.set_ylabel(\"DOPE / a.u.\")\n",
    "ax.set_xticks([1, 2, 3, 4])\n",
    "ax.set_xticklabels([\"training set\", \"training decoded\", \"test set\", \"test decoded\"]);\n",
    "\n",
    "colours=[\"red\", \"orange\", \"blue\", \"cyan\"]\n",
    "for i, violin in enumerate(violins['bodies']):\n",
    "    violin.set_color(colours[i])\n",
    "    violin.set_alpha(1)\n",
    "\n",
    "for partname in ('cbars','cmins','cmaxes','cmeans'):\n",
    "    vp = violins[partname]\n",
    "    vp.set_edgecolor(\"k\")\n",
    "    vp.set_linewidth(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. full latent space characterization <a class=\"anchor\" id=\"ref4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will grid sample the latent space. To this end, we start by identifying the region of interest defined by the coordinates of the training set projected into the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 50\n",
    "bx = (np.max(z_training[:, 0]) - np.min(z_training[:, 0]))*0.1 # 10% margins on x-axis\n",
    "by = (np.max(z_training[:, 1]) - np.min(z_training[:, 1]))*0.1 # 10% margins on y-axis\n",
    "xvals = np.linspace(np.min(z_training[:, 0])-bx, np.max(z_training[:, 0])+bx, samples)\n",
    "yvals = np.linspace(np.min(z_training[:, 1])-by, np.max(z_training[:, 1])+by, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> depending on the sampling granularity, this operation can take a long time! Calculating the DOPE score of a 50x50 grid can take ~20 minutes. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Evaluate re-encoding error <a class=\"anchor\" id=\"ref41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each position in the latent space is decoded, then encoded, the decoded yet again. We assess the drift in latent space upon this iteration and the difference in two consecutive decoded structures with L2 norms. This acts as a heuristic for the precision of the neural network: the smaller these numbers, the more precise the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_z = np.zeros((len(xvals), len(yvals))) # L2 norms in latent space (\"drift\")\n",
    "surf_c = np.zeros((len(xvals), len(yvals))) # L2 norms in Cartesian space\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for x, i in enumerate(xvals):\n",
    "        for y, j in enumerate(yvals):\n",
    "    \n",
    "            # take latent space coordinate (1) and decode it (2)\n",
    "            z1 = torch.tensor([[[i,j]]]).float()\n",
    "            s1 = network.decode(z1)[:,:,:training_set.shape[2]]\n",
    "            \n",
    "            # take the decoded structure, re-encode it (3) and then decode it (4)\n",
    "            z2 = network.encode(s1)\n",
    "            s2 = network.decode(z2)[:,:,:training_set.shape[2]]\n",
    "            \n",
    "            surf_z[x,y] = np.sum((z2.numpy().flatten()-z1.numpy().flatten())**2) # Latent space L2, i.e. (1) vs (3)\n",
    "            surf_c[x,y] = np.sum((s2.numpy().flatten()-s1.numpy().flatten())**2) # Cartesian L2, i.e. (2) vs (4)\n",
    "            \n",
    "surf_c = np.sqrt(surf_c)\n",
    "surf_z = np.sqrt(surf_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot error surfaces for L2 norms in the latent and Cartesian space, and compare the two. For visualisation purposes, we take the log of both quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(xvals, yvals)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.set_title(\"Latent space L2\")\n",
    "ax.pcolormesh(X, Y, np.log(surf_z))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.set_title(\"3D space L2\")\n",
    "ax.pcolormesh(X, Y, np.log(surf_c))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.set_xlabel(\"Latent space L2\")\n",
    "ax.set_ylabel(\"3D space L2\")\n",
    "ax.plot(surf_z.flatten(), surf_c.flatten(), \".\", alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that, although in general large drift corresponds to large RMSD, there is not a 1:1 relationship between the two quantities. This is because the latent space is not linear: the same magnitude of displacement in two different regions of the latent space may be associated to displacements of different magnitude in the 3D space. You may see several trends, overlayed, if the neural network has been trained with a collection of different molecular dynamics simulations projecting in different regions of the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Evaluate DOPE score <a class=\"anchor\" id=\"ref42\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the DOPE score of every conformation decoded from the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_dope = np.zeros((len(xvals), len(yvals)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for x, i in enumerate(xvals):\n",
    "        for y, j in enumerate(yvals):\n",
    "    \n",
    "            # take latent space coordinate (1) and decode it (2)\n",
    "            z1 = torch.tensor([[[i,j]]]).float()\n",
    "            s1 = network.decode(z1)[:,:,:training_set.shape[2]]\n",
    "            \n",
    "            crd_mdl = s1[0].permute(1,0).unsqueeze(0).data.cpu().numpy()[:, :training_set.shape[2]]*stdval + meanval  \n",
    "            mol.coordinates = deepcopy(crd_mdl)\n",
    "            mol.write_pdb(\"tmp.pdb\")\n",
    "            s = dope_score(\"tmp.pdb\")\n",
    "            surf_dope[x,y] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(xvals, yvals)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlabel(\"Latent vector 1 / a.u.\")\n",
    "ax.set_ylabel(\"Latent vector 2 / a.u.\")\n",
    "c = ax.pcolormesh(x, y, surf_dope.T)\n",
    "#ax.plot(z_training[:, 0], z_training[:, 1], color=\"white\", alpha=0.5)\n",
    "cbar = fig.colorbar(c, ax=ax)\n",
    "cbar.set_label(\"DOPE score / a.u.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of this overview. The methods described here are implemented in dedicated classes in the `MolearnAnalysis.py`. Have a look at the jupyter notebook `molearn_GUI_analysis.ipynb` to see it in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA MATERIAL (work in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search best matching structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained molearn with conformations of MurD in its closed and open state, and then wanted to see whether it could predict a suitable intermediate conformation. In this benchmark case, an atomic structure of the intermediate structure has been already trapped and solved. Before attempting to see whether we can used the neural network to predict that conformation, the first question we can ask is: \"*What is the best intermediate the neural network can generate?*\". In an ideal scenario, projecting the known intermediate structure into the latent space should land in a region that, when decoded, produces a structure of low RMSD with the input. However, adjacent regions might do a slightly better job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am interesting plot, is one where the latent space is coloured as a function of how closely it resembles a target structure. In this example, we pick a random conformation from the test set and compare a grid of the latent space to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test_set[0][20]\n",
    "distance, xvals, yavals = MA.scan_error_from_target(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(xvals, yvals)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_title(\"RMSD from target\")\n",
    "ax.pcolormesh(X, Y, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scanning a whole landscape is not very efficient if we only want to know what is the best the neural network can do. So, we can instead search the latent space, looking to the region generating the best possible match vs our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def latent(x):\n",
    "   \n",
    "    global network\n",
    "    global stdval\n",
    "    global meanval\n",
    "    global crd_target\n",
    "    \n",
    "    crd_mdl = generate(network, np.array([[x]]), stdval, meanval)\n",
    "    rmsd = np.sqrt(np.sum((crd_target.flatten()-crd_mdl.flatten())**2)/crd_mdl.shape[1])\n",
    "    \n",
    "    return rmsd\n",
    "    \n",
    "## target must be a Tensor representation of the structure to encode\n",
    "## can be loaded with \"load_data\"\n",
    "# test_set = load_data(test_set_file, atoms = [\"CA\", \"C\", \"N\", \"CB\", \"O\"], device=device)[0]\n",
    "# here, we will just take a structure from the test set as example\n",
    "target = test_set[20].unsqueeze(0) #target as normalized tensor\n",
    "crd_target = target.permute(0, 2, 1).data.cpu().numpy()*stdval + meanval # target as 3D structure\n",
    "\n",
    "# set initial guess as projection into latent space of target\n",
    "with torch.no_grad():\n",
    "    z = network.encode(target.float())\n",
    "    z_test_tmp = z.data.cpu().numpy()[:, :, 0]\n",
    "\n",
    "rmsd_init = latent(z_test_tmp[0])\n",
    "print(\"init: %s -> %s\"%(z_test_tmp[0], rmsd_init))\n",
    "\n",
    "res = minimize(latent, x0=z_test_tmp)\n",
    "print(\"best: %s -> %s\"%(res.x, res.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can carry out the operation above for every structure in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsd_refine = []\n",
    "crds_post = []\n",
    "for i in range(len(test_set)):\n",
    "\n",
    "    print(i)\n",
    "    target = test_set[i].unsqueeze(0) #target as normalized tensor\n",
    "    crd_target = target.permute(0, 2, 1).data.cpu().numpy()*stdval + meanval # target as 3D structure\n",
    "\n",
    "    # set initial guess as projection into latent space of target\n",
    "    with torch.no_grad():\n",
    "        z = network.encode(target.float())\n",
    "        z_test_tmp = z.data.cpu().numpy()[:, :, 0]\n",
    "\n",
    "    rmsd_init = latent(z_test_tmp[0])\n",
    "    print(f'> init: {z_test_tmp[0]} -> {rmsd_init:.4f} A')\n",
    "\n",
    "    res = minimize(latent, x0=z_test_tmp)\n",
    "    print(f'> init: {res.x} -> {res.fun:.4f} A')\n",
    "    \n",
    "    rmsd_refine.append([rmsd_init, res.fun])\n",
    "    crds_post.append(res.x)\n",
    "\n",
    "rmsd_refine = np.array(rmsd_refine)\n",
    "crds_post = np.array(crds_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the raw RMSD distribution (i.e. the RMSD between input and decoded test set structure) to the minimal RMSD (i.e. that involving the best possible model the neural network can generate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'raw RMSD: {np.mean(rmsd_refine[:, 0]):.3f} pm {np.mean(rmsd_refine[:, 0]):.3f} A')\n",
    "print(f'minimal RMSD: {np.mean(rmsd_refine[:, 1]):.3f} pm {np.mean(rmsd_refine[:, 1]):.3f} A')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(rmsd_refine[:, 0], rmsd_refine[:, 1], \"r.\")\n",
    "ax.plot([np.min(rmsd_refine), np.max(rmsd_refine)], [np.min(rmsd_refine), np.max(rmsd_refine)], \"k-\", alpha=0.5)\n",
    "ax.set_xlabel(\"raw RMSD / $\\AA$\")\n",
    "ax.set_ylabel(\"minimal RMSD / $\\AA$\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.violinplot([rmsd_refine[:, 0], rmsd_refine[:, 1]], showmeans=True)\n",
    "ax.set_ylabel(\"RMSD / $\\AA$\")\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels([\"raw\", \"minimal\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Autoencoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function repeats and encode-decode cycle on a neural network, starting from a given target structure if a `Molecule` object is provided as parameter, saves and returns coordinates in a `Molecule` structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_autoencoder(network, target, M=-1, iterations=5, verbose=False):\n",
    "    \n",
    "    inputsize = target.shape[1] #get number of atoms in target structure\n",
    "\n",
    "    if not isinstance(M, int):\n",
    "        #M: place where to store coordinates of generated models (preloading original structure)\n",
    "        crds_ref = target.permute(1,0).unsqueeze(0).data.cpu().numpy()\n",
    "        M.coordinates = crds_ref\n",
    "        M.set_current(0)\n",
    "    else:\n",
    "        print(\"skipping molecule loading...\")\n",
    "\n",
    "    z_val = [] # storage space for latent space projections through iterations\n",
    "\n",
    "    # encode, decode, re-encode, re-decode, re-re-encode, ... (n times)\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # encode and decode (overwrite \"target\" for next iteration)\n",
    "        with torch.no_grad():\n",
    "            z = network.encode(target.unsqueeze(0).float())\n",
    "            target = network.decode(z)[0,:,:training_set.shape[2]]\n",
    "\n",
    "        # store latent space projection projection\n",
    "        pos = z.data.cpu().numpy().flatten()\n",
    "        z_val.append(pos)\n",
    "        \n",
    "        if verbose:\n",
    "            print(i, pos)\n",
    "\n",
    "        if not isinstance(M, int):\n",
    "            # store generated structure upon request\n",
    "            crds_ref = target.permute(1,0).unsqueeze(0).data.cpu().numpy()[0, :inputsize]\n",
    "            M.add_xyz(crds_ref)\n",
    "\n",
    "    if not isinstance(M, int):\n",
    "        return M, z_val\n",
    "    else:\n",
    "        return z_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a structure as starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5 #index of structure\n",
    "target = deepcopy(training_set[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop network from that starting point (then rescaling all molecules coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol2, z_val = loop_autoencoder(network, target, mol, iterations=200)\n",
    "mol2.coordinates *= stdval\n",
    "mol2.coordinates += meanval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all examples in training set and get paths followed by all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 200\n",
    "allz = []\n",
    "d = deepcopy(training_set).float()\n",
    "for i in range(iterations):\n",
    "    with torch.no_grad():\n",
    "        z = network.encode(d)\n",
    "        d = network.decode(z)[:,:,:training_set.shape[2]]\n",
    "        allz.append(z.numpy())\n",
    "        \n",
    "allz = np.array(allz)\n",
    "allz = allz.reshape(iterations, training_set.shape[0], 2).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of autoencoding iteration of single structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_val = np.array(z_val) #evolution of position in 2D latent space \n",
    "r_mat = mol2.rmsd_distance_matrix() # RMSD all-vs-all\n",
    "r_dist = np.diagonal(r_mat, offset=1) #RMSD between consecutive iterations\n",
    "z_dist = np.sqrt(np.sum((z_val[:-1]-z_val[1:])**2,axis=1)) # Euclidean distance in latent space of consecutive iterations\n",
    "mol2.write_pdb(\"test.pdb\") # evolution of molecular models through iterations\n",
    "\n",
    "print(\"Step: \", len(z_dist) ,\". Distance: \", z_dist[-1], \". RMSD: \", r_dist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_training = z.data.cpu().numpy()[:,:,0] #save for later plotting\n",
    "\n",
    "### plot position in latent space ###\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "#if simulation is broken in two parts, plot them in different colours\n",
    "plt.plot(z_training[:, 0], z_training[:, 1], \"k.\")\n",
    "\n",
    "#plot paths followed by all iterations (if True)\n",
    "if True:\n",
    "    for z in allz:\n",
    "        plt.plot(z[:, 0], z[:, 1], \"r-\", alpha=0.2)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"latent vector 1\")\n",
    "ax.set_ylabel(\"latent vector 2\")\n",
    "\n",
    "\n",
    "### plot position in latent space before and after looping ###\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "plt.plot(allz[:, -1, 0], allz[:, -1, 1], \"k.\")\n",
    "\n",
    "ax.set_xlabel(\"latent vector 1\")\n",
    "ax.set_ylabel(\"latent vector 2\")\n",
    "\n",
    "#plot paths of structure of interest (if True)\n",
    "if True:\n",
    "    plt.plot(z_val[:, 0], z_val[:, 1], \"r.\", alpha=1, linewidth=1.0)\n",
    "        \n",
    "### plot evolution of single structure between consecutive itererations ###\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# distances in latent space\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "ax.plot(np.arange(len(z_dist)), z_dist, \"r-\", fillstyle=\"none\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel(\"drift\")\n",
    "\n",
    "# RMSD between original and autoencoded\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "ax.plot(np.arange(len(r_dist)), r_dist, \"r-\", fillstyle=\"none\")\n",
    "ax.set_xlabel(\"step\")\n",
    "ax.set_ylabel(\"RMSD (A)\")\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(z_dist, r_dist[1:], \"k.\")\n",
    "ax.set_xlabel(\"drift\")\n",
    "ax.set_ylabel(\"RMSD (A)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space drift vs reconstruction RMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#projection colored by RMSD\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.scatter(z_training[:, 0], z_training[:, 1], c=rmsd_all, alpha=0.5, edgecolor=\"none\")\n",
    "ax.set_xlabel(\"latent vector 1\")\n",
    "ax.set_ylabel(\"latent vector 2\")\n",
    "\n",
    "#drift vs RMSD\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "dists = np.sqrt((allz[:, 0, 0]-allz[:, 1, 0])**2 + (allz[:, 0, 1]-allz[:, 1, 1])**2)\n",
    "plt.plot(dists, rmsd_all, \"k.\")\n",
    "ax.set_xlabel(\"drift\")\n",
    "ax.set_ylabel(\"RMSD (A)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate DOPE score of all interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymol = bb.Molecule()\n",
    "mymol.import_pdb(\"test.pdb\")\n",
    "\n",
    "testH = mymol.data[\"resname\"].values\n",
    "testH[testH == \"HIE\"] = \"HIS\"\n",
    "testH[testH == \"HID\"] = \"HIS\"\n",
    "mymol.data[\"resname\"] = testH\n",
    "\n",
    "dp = []\n",
    "for i in range(len(mymol.coordinates)):\n",
    "    print(i)\n",
    "    mymol.write_pdb(\"tmp.pdb\", conformations=[i])\n",
    "    s = dope_score(\"tmp.pdb\")\n",
    "    dp.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DOPE of interpolation\n",
    "halt = 100\n",
    "dope = np.array(dp)\n",
    "print(\"interp. DOPE: %6.2f pm %6.2f [%6.2f, %6.2f]\"%(np.mean(dope[:halt]), np.std(dope[:halt]), np.min(dope[:halt]), np.max(dope[:halt])))\n",
    "print(\"DOPE at transition state: %6.2f\"%dope[15])\n",
    "\n",
    "#DOPE of training set\n",
    "dopetrain = np.array(dptrain)\n",
    "print(\"training DOPE: %6.2f pm %6.2f [%6.2f, %6.2f]\"%(np.mean(dopetrain), np.std(dopetrain), np.min(dopetrain), np.max(dopetrain)))\n",
    "\n",
    "# color path followed as a function of DOPE score\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "plt.plot(allz[:, 0, 0], allz[:, 0, 1], \"k.\")\n",
    "\n",
    "ax.set_xlabel(\"latent vector 1\")\n",
    "ax.set_ylabel(\"latent vector 2\")\n",
    "\n",
    "plt.scatter(z_val[0:halt, 0], z_val[0:halt, 1], c=dope[0:halt], alpha=1, linewidth=1.0)\n",
    "    \n",
    "# DOPE score of interpolation compared to training set distribution\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ymin = np.ones(halt)*(np.mean(dopetrain) - np.std(dopetrain))\n",
    "ymax = np.ones(halt)*(np.mean(dopetrain) + np.std(dopetrain))\n",
    "ax.hlines([np.min(dopetrain), np.max(dopetrain)], 0, halt, color=\"k\")\n",
    "ax.fill_between(np.arange(halt), ymin, ymax, color=\"k\", alpha=0.1)\n",
    "ax.plot(np.arange(halt), dope[0:halt], \"r-\")\n",
    "ax.set_xlim([0, halt])\n",
    "ax.set_xlabel(\"interpolation step\")\n",
    "ax.set_ylabel(\"DOPE score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimate velocity of interpolation, and use adaptive sampling to keep it as much as possible constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocity(gen):\n",
    "    \n",
    "    vel = []\n",
    "    for i in range(1, len(gen)):\n",
    "        d = gen[i]-gen[i-1]\n",
    "        v = np.sqrt(np.sum(d**2, axis=1))\n",
    "        vel.append(v)\n",
    "    \n",
    "    return np.array(vel)\n",
    "    \n",
    "crd = np.array([0.412400224561594, 0.19486213635121072, 0.6454603429351535, 0.06663592897203505])\n",
    "crd = crd.reshape((1, int(len(crd)/2), 2))\n",
    "crd = oversample(crd, pts=10)\n",
    "\n",
    "gen = generate(network, crd, stdval, meanval)\n",
    "vel = get_velocity(gen)\n",
    "\n",
    "vel = ((vel-np.min(vel))/np.max(vel)+1)\n",
    "\n",
    "#crd2 = []\n",
    "#for i in range(len(crd[0])-1):\n",
    "#    \n",
    "#    tmp = oversample(np.array([crd[0, i:i+2]]), pts=int(np.mean(vel, axis=1)[i]))\n",
    "#    \n",
    "#    if len(crd2) == 0:\n",
    "#        crd2 = tmp.copy()\n",
    "#    else:\n",
    "#        crd2 = np.concatenate((crd2, tmp), axis=1)\n",
    "#\n",
    "#\n",
    "#gen2 = generate(network, np.array(crd2), stdval, meanval)\n",
    "#vel2 = get_velocity(gen2)\n",
    "\n",
    "plt.plot(np.max(vel, axis=1), marker=\".\")\n",
    "#plt.plot(np.mean(vel2, axis=1), marker=\".\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
