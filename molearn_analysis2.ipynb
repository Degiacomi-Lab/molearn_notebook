{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea02ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "\n",
    "import modeller\n",
    "from modeller import *\n",
    "from modeller.scripts import complete_pdb\n",
    "\n",
    "import MDAnalysis as mda\n",
    "\n",
    "import biobox as bb\n",
    "\n",
    "#edit path as required for your computer (or remove, if you installed molearn via conda-forge)\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\xdzl45\\\\workspace\\\\molearn\\\\src\")\n",
    "from molearn import load_data, Auto_potential, Autoencoder, ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolearnAnalysis(object):\n",
    "    \n",
    "    def __init__(self, network, infile, m=2.0, latent_z=2, r=2, atoms = [\"CA\", \"C\", \"N\", \"CB\", \"O\"]):\n",
    "        \n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        \n",
    "        training_set, meanval, stdval, atom_names, mol, test0, test1 = load_data(infile,\n",
    "                                                                                 atoms = atoms,\n",
    "                                                                                 device=self.device)\n",
    "      \n",
    "        # set residues names with protonated histidines back to generic HIS name (needed by DOPE score function)\n",
    "        testH = mol.data[\"resname\"].values\n",
    "        testH[testH == \"HIE\"] = \"HIS\"\n",
    "        testH[testH == \"HID\"] = \"HIS\"\n",
    "        mol.data[\"resname\"] = testH\n",
    "        \n",
    "        # create an MDAnalysis instance of input protein\n",
    "        mol.write_pdb(\"tmp.pdb\")\n",
    "        self.mymol = mda.Universe('tmp.pdb')\n",
    "\n",
    "        self.training_set = training_set\n",
    "        self.meanval = meanval\n",
    "        self.stdval = stdval\n",
    "        self.mol = mol\n",
    "        self.atoms = atoms\n",
    "        \n",
    "        checkpoint = torch.load(networkfile, map_location=self.device)\n",
    "        self.network = Autoencoder(m=m, latent_z=latent_z, r=r).to(self.device)\n",
    "        self.network.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        for modulelist in [self.network.encoder, self.network.decoder]:\n",
    "            for layer in modulelist:\n",
    "                if type(layer)==torch.nn.BatchNorm1d:\n",
    "                    layer.momentum=1.0\n",
    "                elif type(layer)==ResidualBlock:\n",
    "                    for rlayer in layer.conv_block:\n",
    "                        if type(rlayer)==torch.nn.BatchNorm1d:\n",
    "                            rlayer.momentum=1.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.network.decode(self.network.encode(self.training_set.float()))\n",
    "\n",
    "        self.network.eval()\n",
    "        #os.remove(\"tmp.pdb\")\n",
    "        os.remove(\"rmsd_matrix.npy\")\n",
    "    \n",
    "    \n",
    "    def load_test(self, infile):\n",
    "\n",
    "        test_set, _, _, _, _, _, _ = load_data(infile, atoms = self.atoms, device=self.device)\n",
    "        if test_set.shape[2] != self.training_set.shape[2]:\n",
    "            raise Exception(f'number of d.o.f. differs: training set has {self.training_set.shape[2]}, test set has {test_set.shape[2]}')\n",
    "\n",
    "        return test_set\n",
    "\n",
    "\n",
    "    def get_error(self, dataset=\"\", align=False):\n",
    "        '''\n",
    "        Calculate the reconstruction error of a dataset encoded and decoded by a trained neural network\n",
    "        '''\n",
    "\n",
    "        if dataset == \"\":\n",
    "            dataset = self.training_set\n",
    "\n",
    "        z = self.network.encode(dataset.float())\n",
    "        decoded = self.network.decode(z)[:,:,:dataset.shape[2]]\n",
    "\n",
    "        err = []\n",
    "        for i in range(dataset.shape[0]):\n",
    "\n",
    "            crd_ref = dataset[i].permute(1,0).unsqueeze(0).data.cpu().numpy()*self.stdval + self.meanval\n",
    "            crd_mdl = decoded[i].permute(1,0).unsqueeze(0).data.cpu().numpy()[:, :dataset.shape[2]]*self.stdval + self.meanval #clip the padding of models  \n",
    "\n",
    "            if align: # use Molecule Biobox class to calculate RMSD\n",
    "                self.mol.coordinates = deepcopy(crd_ref)\n",
    "                self.mol.set_current(0)\n",
    "                self.mol.add_xyz(crd_mdl[0])\n",
    "                rmsd = self.mol.rmsd(0, 1)\n",
    "            else:\n",
    "                rmsd = np.sqrt(np.sum((crd_ref.flatten()-crd_mdl.flatten())**2)/crd_mdl.shape[1]) # Cartesian L2 norm\n",
    "\n",
    "            err.append(rmsd)\n",
    "\n",
    "        return np.array(err)\n",
    "\n",
    "\n",
    "    def get_dope(self, dataset=\"\"):\n",
    "\n",
    "        if dataset == \"\":\n",
    "            dataset = self.training_set    \n",
    "\n",
    "        z = self.network.encode(dataset.float())\n",
    "        decoded = self.network.decode(z)[:,:,:dataset.shape[2]]\n",
    "\n",
    "        dope_dataset = []\n",
    "        dope_decoded = []\n",
    "        for i in range(dataset.shape[0]):\n",
    "\n",
    "            # calculate DOPE score of input dataset\n",
    "            crd_ref = dataset[i].permute(1,0).unsqueeze(0).data.cpu().numpy()*self.stdval + self.meanval\n",
    "            self.mol.coordinates = deepcopy(crd_ref)\n",
    "            self.mol.write_pdb(\"tmp.pdb\")\n",
    "            s = dope_score(\"tmp.pdb\")\n",
    "            dope_dataset.append(s)\n",
    "\n",
    "            # calculate DOPE score of decoded counterpart\n",
    "            crd_mdl = decoded[i].permute(1,0).unsqueeze(0).data.cpu().numpy()[:, :dataset.shape[2]]*self.stdval + self.meanval  \n",
    "            self.mol.coordinates = deepcopy(crd_mdl)\n",
    "            self.mol.write_pdb(\"tmp.pdb\")\n",
    "            s = dope_score(\"tmp.pdb\")\n",
    "            dope_decoded.append(s)\n",
    "\n",
    "        return dope_dataset, dope_decoded\n",
    "\n",
    "\n",
    "    def scan_error(self, samples = 50):\n",
    "\n",
    "        z = network.encode(training_set.float())\n",
    "        z_training = z.data.cpu().numpy()[:, :, 0]\n",
    "\n",
    "        bx = (np.max(z_training[:, 0]) - np.min(z_training[:, 0]))*0.1 # 10% margins on x-axis\n",
    "        by = (np.max(z_training[:, 1]) - np.min(z_training[:, 1]))*0.1 # 10% margins on y-axis\n",
    "        xvals = np.linspace(np.min(z_training[:, 0])-bx, np.max(z_training[:, 0])+bx, samples)\n",
    "        yvals = np.linspace(np.min(z_training[:, 1])-by, np.max(z_training[:, 1])+by, samples)\n",
    "\n",
    "        surf_z = np.zeros((len(xvals), len(yvals))) # L2 norms in latent space (\"drift\")\n",
    "        surf_c = np.zeros((len(xvals), len(yvals))) # L2 norms in Cartesian space\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for x, i in enumerate(xvals):\n",
    "                for y, j in enumerate(yvals):\n",
    "\n",
    "                    # take latent space coordinate (1) and decode it (2)\n",
    "                    z1 = torch.tensor([[[i,j]]]).float()\n",
    "                    s1 = self.network.decode(z1)[:,:,:self.training_set.shape[2]]\n",
    "\n",
    "                    # take the decoded structure, re-encode it (3) and then decode it (4)\n",
    "                    z2 = self.network.encode(s1)\n",
    "                    s2 = self.network.decode(z2)[:,:,:self.training_set.shape[2]]\n",
    "\n",
    "                    surf_z[x,y] = np.sum((z2.numpy().flatten()-z1.numpy().flatten())**2) # Latent space L2, i.e. (1) vs (3)\n",
    "                    surf_c[x,y] = np.sum((s2.numpy().flatten()-s1.numpy().flatten())**2) # Cartesian L2, i.e. (2) vs (4)\n",
    "\n",
    "        return np.sqrt(surf_c), np.sqrt(surf_z)\n",
    "\n",
    "\n",
    "    def _dope_score(self, fname):\n",
    "        env = Environ()\n",
    "        env.libs.topology.read(file='$(LIB)/top_heav.lib')\n",
    "        env.libs.parameters.read(file='$(LIB)/par.lib')\n",
    "        mdl = complete_pdb(env, fname)\n",
    "        atmsel = Selection(mdl.chains[0])\n",
    "        score = atmsel.assess_dope()\n",
    "        return score\n",
    "\n",
    "\n",
    "    def scan_dope(self, samples = 50):\n",
    "\n",
    "        surf_dope = np.zeros((len(xvals), len(yvals)))\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for x, i in enumerate(xvals):\n",
    "                for y, j in enumerate(yvals):\n",
    "\n",
    "                    # take latent space coordinate (1) and decode it (2)\n",
    "                    z1 = torch.tensor([[[i,j]]]).float()\n",
    "                    s1 = self.network.decode(z1)[:,:,:self.training_set.shape[2]]\n",
    "\n",
    "                    crd_mdl = s1[0].permute(1,0).unsqueeze(0).data.cpu().numpy()[:, :self.training_set.shape[2]]*self.stdval + self.meanval  \n",
    "                    self.mol.coordinates = deepcopy(crd_mdl)\n",
    "                    self.mol.write_pdb(\"tmp.pdb\")\n",
    "                    surf_dope[x,y] = self._dope_score(\"tmp.pdb\")\n",
    "\n",
    "\n",
    "    def generate(self, crd):\n",
    "        '''\n",
    "        generate a collection of protein conformations, given (Nx2) coordinates in the latent space\n",
    "        ''' \n",
    "        with torch.no_grad():\n",
    "            z = torch.tensor(crd.transpose(1, 2, 0)).float()   \n",
    "            s = self.network.decode(z)[:, :, :self.training_set.shape[2]].numpy().transpose(0, 2, 1)\n",
    "\n",
    "        return s*self.stdval + self.meanval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cf390",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930348c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkfile = \"C:\\\\temp\\\\Dropbox\\\\Durham\\\\data\\\\neural_net\\\\conv1d-physics-path_B.pth\"\n",
    "training_set_file = \"MurD_closed_open_strided.pdb\"\n",
    "test_set_file = \"MurD_closed_apo_strided.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA = MolearnAnalysis(networkfile, training_set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = MA.load_test(test_set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train = MA.get_error()\n",
    "r2_test = MA.get_error(test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
